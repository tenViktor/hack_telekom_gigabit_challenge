from langchain import PromptTemplate, LLMChain
from langchain.chat_models import ChatOpenAI
import os


class ExploitGenerator:
    def __init__(self):
        self.llm = ChatOpenAI(
            model_name="gpt-4",
            temperature=0.2,
            openai_api_key=os.getenv("OPENAI_API_KEY"),
        )

        self.exploit_template = """
        Given the following vulnerability information, generate a safe Playwright test script to verify its existence.

        Vulnerability Type: {vuln_type}
        CWE: {cwe}
        Target URL: {target_url}
        Endpoint: {endpoint}
        Parameters: {parameters}

        Requirements:
        1. The script should not cause any damage or data modification
        2. Use only read operations where possible
        3. Include proper error handling
        4. Take screenshots of the evidence
        5. Return detailed results

        Similar vulnerabilities for reference:
        {similar_vulns}

        Generate a Playwright script that:
        1. Sets up the test environment
        2. Attempts to verify the vulnerability
        3. Captures evidence
        4. Cleans up safely

        Script:
        """

        self.prompt = PromptTemplate(
            input_variables=[
                "vuln_type",
                "cwe",
                "target_url",
                "endpoint",
                "parameters",
                "similar_vulns",
            ],
            template=self.exploit_template,
        )

    async def generate_exploit(self, vulnerability_info: dict) -> str:
        chain = LLMChain(llm=self.llm, prompt=self.prompt)

        response = await chain.arun(**vulnerability_info)

        # Validate generated script
        if self._validate_script(response):
            return response
        return None

    def _validate_script(self, script: str) -> bool:
        # Check for dangerous operations
        dangerous_patterns = [
            "delete",
            "drop",
            "truncate",
            "exec(",
            "eval(",
            "system(",
            "rm -rf",
        ]
        return not any(pattern in script.lower() for pattern in dangerous_patterns)
